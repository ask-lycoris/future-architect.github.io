---
title: "言語処理学会 （NLP2025）参加報告"
date: 2025/04/21 00:00:01
postid: b
tag:
  - 参加レポート
  - 学会
  - NLP
  - NLP2025
category:
  - DataScience
thumbnail: /images/20250421b/thumbnail.jpg
author: 松岡翔平
lede: "2025年3月10日（月）〜3月14日（金）において長崎出島メッセにて開催されました[言語処理学会第31回年次大会（NLP2025）]に初参加してきました。当社はプラチナスポンサーとして参加しており、私含めてSAIG7名がオンサイトで参加し、スポンサーブースでの会社紹介及びポスター発表を行いました。"
---
[春の入門祭り2025](/articles/20250413a/) 4日目です。

# はじめに

はじめまして。フューチャー株式会社の松岡と申します。私は2024年7月に当社に入社し、現在はStrategic AI Group（SAIG）の一員として大規模言語モデル（LLM）の社会実装に取り組んでいます。私自身、LLMは大学院時代の専門領域ではありませんでしたが、LLMに興味を持ち、SAIGに所属しています。現在はNLP畑出身の専門家の方々と日々の業務と技術の研鑽に取り組んでいます。

そんな私が、2025年3月10日（月）〜3月14日（金）において長崎出島メッセにて開催されました[言語処理学会第31回年次大会（NLP2025）](https://anlp.jp/nlp2025/)に初参加してきました。

当社はプラチナスポンサーとして参加しており、私含めてSAIG7名がオンサイトで参加し、スポンサーブースでの会社紹介及びポスター発表を行いました。

私は社会人1年目の新参者であるにもかかわらず、SAIG内部で参加者を募集している際に「私も参加したい」と声を上げたところ、参加できることとなりました！！快く送ってくださったSAIGの方々には感謝してもしきれません。

<img src="/images/20250421b/IMG_7884.jpg" alt="" width="1200" height="900" loading="lazy">

# 言語処理学会とは

言語処理学会はNLP分野における国内最大の学会で、毎年3月に開催されています。年次大会は今年で31回目となります。口頭発表は5会場に加えポスター発表2会場の合計7会場に分かれ実施され、最終日にはワークショップと盛りだくさんの内容です。

参加者数は当日登録含まない一日目時点で2248名、発表件数777件、スポンサー数103団体と、過去最大の参加者数、発表件数、スポンサー数であり、参加していて非常に活気がある学会でした。

実際に参加をしてみて、独特だなと思ったのはslackの運用です。NLP2025ではslackのワークスペースを独自に開設しており、聞きたい発表のチャンネルに入ることで、そちらから質問をすることができました。発表内容に関する議論も積極的に行われており、その議論から知見も多く得られたと同時に言語処理学会の熱気を感じ取ることができました。

# スポンサーブース

企業ブースを出展しAI案件実績の紹介と人材募集を行いました。当社をご存じなかった方々にもアピールでき、研究についてや案件内容に用いた技術についてのディスカッションなど、大変盛り上がりました。

主に学生の方へ向けては、会社紹介のパンフレットと共にノベルティとしてトートバッグを配布しながら、会社についての紹介をしました。たくさんの方々に来ていただき、大盛況でした。

<img src="/images/20250421b/IMG_6636.jpg" alt="" width="1200" height="605" loading="lazy">

# 投稿論文の紹介

当社は、NLP2025において著者・共著者を含めて合計5件の論文を投稿しました。

本章ではこれらの5件の論文について簡単に紹介します。

## [[P2-13]「数」に着目したLLMの多言語能力の検証](https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/P2-13.pdf)

この論文では、大規模言語モデル（LLM）の多言語能力を、LLMに単語や文の文字数を数えさせるカウントタスクと、指定した文字数で文を生成させる生成長制御タスクの2つの「数」に着目したタスクによって検証しました。

文字列カウントタスクでは、単語のカウントは高い精度を示しましたが、文のカウントでは精度の低下が確認されました。

生成長制御タスクでは、ヨーロッパ言語はヨーロッパ言語の指示で生成させる方が、アジア言語はアジア言語の指示で生成させる方が精度が高い傾向が見られました。また、中国語と日本語を生成させた場合、生成結果の平均長が指定した50文字よりも短くなる傾向がありました。さらに、日本語で指示を与えた場合、英語、スペイン語、ポルトガル語の生成結果が著しく長くなる現象が確認されました。

## [[P2-24] Wikipediaリダイレクト情報を活用したエンティティベース質問応答データセットの構築](https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/P2-24.pdf)

この論文では、大規模言語モデル（LLM）がエンティティをどのように記憶しているかを調査するために、Wikipediaのリダイレクト情報を活用した新しい質問応答データセットRedirectQAを提案しています。

RedirectQAでは複数の表層を考慮に入れることが可能であることが特徴で、LLMがエンティティ自体を記憶しているのか、それとも特定の表層を記憶しているのかをより詳細な分析が可能です。

また、Pythiaの12Bモデルを用いて、作成したデータセットを用いて、LLMの記憶がエンティティではなく表層に紐づいているかの評価を行いました。

その結果、LLMは代表的な表層を記憶している場合でも、必ずしもすべてのリダイレクト表層を記憶しているわけではないことが示されました。また、表記揺れのような表層の差異が小さい場合には、記憶が紐づきやすい傾向があることも示唆されました。

## [[Q6-9] 日本語によるコード生成能力の正確な評価に向けて](https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q6-9.pdf)

この論文では、日本語によるコード生成能力の正確な評価を目的として複数のプログラミング言語に対応したコード生成ベンチマークであるMultiPL-Eを日本語化することで、JavaおよびC++の評価データセットJMultiPL-Eを構築し、Llama-3.1-8B-Instruct（Llama）とLlama 3.1-8Bに対して日本語で継続事前学習を行ったLlama-3.1-Swallow-8B-Instruct-v0.1（Swallow）という2つのLLMモデルを用いて、日本語でのPython、Java、C++のコード生成能力と継続事前学習がコード生成能力に与える影響を調査しました。

日本語で継続事前学習を行ったSwallowでは、日本語と英語の指示文によるスコア差の縮小が確認されました。また、SwallowはJavaおよびC++において、Llamaよりも高い日本語でのコード生成能力を示しました。

## [[Q8-18]新聞ドメインにおける大規模言語モデルの継続事前学習と下流タスクデータ量の関係](https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q8-18.pdf)

この論文では、大規模言語モデルを特定のドメインに適応させるための継続事前学習の有無と教師ありファインチューニング（SFT）に用いるデータ量が性能に与える影響について、新聞ドメインの見出し生成タスクを対象に分析しています。

分析では新聞記事として信濃毎日新聞株式会社が自社で執筆した紙面記事の本文、見出しを用いて、Llama-3.1-Swallow8B-v0.1、新聞記事本文で継続事前学習を行ったモデル、日本語Wikipediaで継続事前学習を行ったモデルの3つのモデルに対して見出し生成タスクへのSFTを行い、性能を評価しました。

評価の結果、SFTの学習データ量によらず基本的に新聞記事本文で継続事前学習を行ったモデルの性能が高いことを確認しました。特に、SFTの学習データが50件など極端に少ない場合に継続事前学習の効果が大きい可能性が示唆されました。

## [[D9-4] MQM-Chat:対話翻訳のための多次元品質指標](https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/D9-4.pdf)

この論文では、従来の翻訳評価指標では捉えきれない、曖昧さ、流行語、対話の不整合性などの問題に対処するための、対話翻訳における特有の課題を評価するための新しい指標「MQM-Chat」が提案されています。

MQM-Chatは、誤訳、省略・追加、用語・固有名詞の誤り、不自然なスタイル、曖昧さ、流行語、対話の不整合性という7つのエラータイプで構成されており、特に最後の3つのエラータイプ（曖昧さ、流行語、対話の不整合性）が、対話翻訳に特化した新しい分類です。

提案されたMQM-Chatを用いて、5つの機械翻訳モデルによる中英・日英の対話翻訳を評価した結果、MQM-Chatは既存のMQMよりも詳細なエラー分類を提供し、標準MQMでは捉えきれなかった対話特有の問題を明確に識別できることが示されました。

# 社員が選ぶNLP2025イチオシ論文の紹介

本章では、NLP2025で発表された論文の中で、NLP2025に参加した7名の社員が選んだイチオシの論文を簡単に紹介します。

##  [[Q2-4]llm-jp-judge:日本語LLM-as-a-Judge評価ツール](https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q2-4.pdf)

この論文では、LLMの応答を自動評価するLLM-as-a-Judgeという手法を、日本語LLMに対して統一的に扱うためのツール「Llm-jp-judge」の提案と、評価ツールを用いた評価とメタ評価との比較を実施しています。

興味深かったのは、人によって評価する場合と、評価ツールを用いるLLM（gpt-4o）による評価の比較において、LLMの方が評価を高くつける傾向にあることが示されているということです。にもかかわらず、相関値を比較してみると正確性を除き、すべての評価指標で高い相関を得られていることが結果で示されていました。

LLMの自動評価ツールが注目されている中、人間よりも高い評価をつけるとはいえ、高い相関性を持つことが判明したことは今後の自動評価ツールの開発において非常に良い知見であると考え、こちらの発表を取り上げました。（松岡）

## [[Q2-13]架空語に対するLLMの知ったかぶりの自動評価](https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q2-13.pdf)

この研究では尤もらしい架空語を生成しLLMにその意味を答えさせることで、LLMが引き起こす幻覚の分析を行っています。

架空語の生成では実際に存在しそうな尤もらしい架空語を生成する手法を提案しており、LLMの幻覚を誘発しやすい設定での実験を可能にしています。実験では尤もらしい架空語ほどLLMによる捏造が発生しやすいことを示しており、さらに追加実験ではRAGに近い設定で架空語に対する挙動を分析しており、たとえ架空語の意味をLLMに与えたとしても既存の知識に依存して幻覚が発生してしまう、という興味深い結果が得られています。

RAGなどの文脈において専門用語などのLLMにとって未知の単語を扱うケースは頻繁に発生し、その影響を分析することは非常に重要なタスクだと考えられるため、こちらの発表を取り上げさせていただきました。（神戸）

## [[P7-1]対照学習を用いたhallucination検出手法](https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/P7-1.pdf)

LLMの出力に対するhallucination検出タスクにおいて、対照学習を用いて検出モデルの学習を行うことで検出精度を向上させた研究です。

hallucinationを含む文章には入力文章と矛盾する情報などが含まれることから、入力文章とは乖離する埋め込み表現を持っていると仮定し、入力文章と正例（hallucinationのない文章）との埋め込みを近づけ、負例（hallucinationを含む文章）との埋め込みを遠ざけるようなtriplet lossと、通常の分類問題のlossを組み合わせることで検出器を学習しています。
既存のデータセットを用いた評価の結果、特にQAタスク・要約タスクにおけるhallucination検出精度が大きく向上したようです。

LLMのhallucinationは未だ課題であるなかで、埋め込み表現に着目したアプローチで大幅な精度向上を実現していることや、特に応用範囲の広いQA・要約タスクで効果が高いことから実用的にも重要な知見であると考え挙げさせていただきました。（岸波）

## [[Q3-25]VLMによるソフトウェア図表の理解に関する予備調査](https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q3-25.pdf)

この研究では、ソフトウェア開発におけるVLMの活用を目指し、ソフトウェア図表理解能力を評価するベンチマーク「JSWEMU」を開発しました。

このベンチマークは、図表の画像と設問で構成されており、描画スタイル、図表の種類ごとにVLMの図表理解能力を評価することができます。
実験では、描画スタイルの正答率への影響は限定的で、図表の種類やモデルにより理解能力に差が生じるという興味深い結果が得られています。

VLMの得意/不得意な領域が見えてくれば、実際の開発での活用に一歩近づくのではないかと思います。ソフトウェア開発での実応用に向けて意義のある研究だと思い、この研究を挙げさせていただきました。（加藤）

## [[D1-5]テキストの埋め込み表現に基づくデータ増強を用いたX（旧Twitter）における日本語の皮肉検出](https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/D1-5.pdf)

皮肉検出のための新しいデータ増強手法の研究です。

皮肉は感情分析誤りの原因となるため、検出が必要ですが、分類器の学習に十分な規模の日本語皮肉データの収集は困難です。そこで、少数のサンプルを基に、類似データを作るデータ増強が有効です。

従来の増強手法は、文章の意味を表す埋め込みにノイズを加えるといった方法で微妙に異なるサンプルを作りますが、皮肉文においては「君はおめでたい人だ」を「君は喜ばしい人だ」のように変えると皮肉らしさがなくなるように、繊細なニュアンスを損なう可能性があります。そこで提案手法では、皮肉らしさに影響を与えない部分を特定し、その埋め込みにノイズを加えることで、ニュアンスを保ったままデータを増強する手法を提案しました。増強後データを利用して学習したモデルは、従来手法より高精度となりました。

この研究は、レビュー分析やコミュニケーション円滑化など実社会での応用に加え、皮肉という言語現象の理解にも貢献する、意義深いものだと考え、挙げさせていただきました。（肥合）

## [ワークショップ1] podnikáníゴရှウ≫的聲音毎回強いメッセージを提供するかどうか模案まれたပေမယယယ့် ตอน ไป のこと歓通だった。

言語モデルを破壊しそうなタイトルですが...最終日のワークショップで非常に盛り上がった発表です。

こちらの研究では、翻訳のタスクのおいて“どう見てもおかしいのに評価値だけがなぜか高い”評価指標ハック文を作成するため、ベクトル検索の文脈等で問題となるhubnessに着目しています。

この発表では、ある評価指標においてあらゆる入力文でスコアが高くなるような翻訳文のベクトル表現（hubベクトル）を学習 → 文埋め込みから文に復元するような「文エンコーダの逆関数」を学習し、エンコードした際にhubベクトルに近くなるような自然（？）言語文を復元するという手順を踏んでいます。

得られた文を初期解として1単語ずつ評価値をより高くできるように置換すると、タイトルのようにまったく意味をなさないにも関わらず、翻訳コンペティションの上位サブミッションにも匹敵するスコアが出てしまうのは驚きです。

ワークショップ内の別の発表で、LLMベースの翻訳評価は“この翻訳はプロの翻訳家が作成したものです”と入れるだけで過大評価するといった報告もされていましたが、このようなモデルベース評価の脆さは昨今注目されるllm-as-a-judgeに対しても警鐘を鳴らす実りある内容だと感じました。（藤井）

## [[P1-19] ニューラルかな漢字変換システム Zenzai](https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/P1-19.pdf)

高性能かつ高速なニューラルかな漢字変換システムを考案した研究です。

通常かな漢字変換システムは統計的機械学習に基づいています。時折ニューラルネットワークを用いたモデルが提案され精度面で統計モデルを上回ることがあるものの、実行時の速度的な観点から中々実用に至りませんでした。
この問題に対して、本研究ではニューラル言語モデルの推論時に、投機的デコーディングを併用することで推論を高速化し、実用に耐えうるレベルの速度と精度を両立しました。

投機的デコーディングは本来数十B〜数百Bクラスの大規模言語モデルの推論を高速化する手法として提案されましたが、それを遥かに小さいかな漢字変換モデルに対して適用したという点が興味深く、これによりニューラルかな漢字変換モデルが実用レベルとなった点は大きな貢献だと考えています。（森下）

# さいごに

NLPの学会初参加だったのですが、非常に多くの知見を得ることができました、特に研究の熱気に当てられ自分もさらに技術の探求を頑張らねばとやる気を新たにしています。

NLP2025は大学院時代の研究分野から垣根を大きく超えた先の分野ではありましたが、数多くの研究を見ることができ、とても良い刺激になりました。

現在SAIGではともに働くメンバーを募集しています。特にNLP分野における社会実装のニーズは根強く、多くの仲間を必要としているところです。キャリア採用ページでは[NLPシニアエンジニア](https://open.talentio.com/r/1/c/future/pages/76795)をはじめ、[NLPリサーチエンジニア](https://open.talentio.com/r/1/c/future/pages/90909)及び[NLPエンジニア](https://open.talentio.com/r/1/c/future/pages/90906)も同じく絶賛募集中です。条件等応相談ですので、我こそはという読者の方は是非先のリンクよりご応募をお待ちしております。

ほかにも幅広く[新卒採用](https://www.future.co.jp/recruit/recruit/rec-fresh/)および[キャリア採用](https://www.future.co.jp/recruit/recruit/rec-career/)を募集中です。興味のある方は是非一緒に働きましょう。よろしくお願いします！
